{
    "EleutherAI/gpt-neo-125m": {
        "jtatman/databricks-dolly-8k-qa-open-close": {
            "bleu": 0.02151,
            "rouge": 0.10597
        },
        "lionelchg/dolly_open_qa": {
            "bleu": 0.01601,
            "rouge": 0.09841
        },
        "tatsu-lab/alpaca": {
            "bleu": 0.01733,
            "rouge": 0.10234
        },
        "truthful_qa": {
            "bleu": 0.00913,
            "rouge": 0.05221
        }
    },
    "EleutherAI/pythia-160m-deduped": {
        "jtatman/databricks-dolly-8k-qa-open-close": {
            "bleu": 0.02282,
            "rouge": 0.10471
        },
        "lionelchg/dolly_open_qa": {
            "bleu": 0.01259,
            "rouge": 0.08761
        },
        "tatsu-lab/alpaca": {
            "bleu": 0.01679,
            "rouge": 0.10385
        },
        "truthful_qa": {
            "bleu": 0.00667,
            "rouge": 0.04617
        }
    },
    "Helsinki-NLP/opus-mt-en-fr": {
        "enimai/MuST-C-fr": {
            "bleu": 0.45351
        }
    },
    "Helsinki-NLP/opus-mt-ru-en": {
        "shreevigneshs/iwslt-2023-en-ru-train-val-split-0.2": {
            "bleu": 0.25689
        }
    },
    "Helsinki-NLP/opus-mt-ru-es": {
        "nuvocare/Ted2020_en_es_fr_de_it_ca_pl_ru_nl": {
            "bleu": 0.23904
        }
    },
    "JackFram/llama-68m": {
        "jtatman/databricks-dolly-8k-qa-open-close": {
            "bleu": 0.01666,
            "rouge": 0.08852
        },
        "lionelchg/dolly_open_qa": {
            "bleu": 0.01337,
            "rouge": 0.09282
        },
        "tatsu-lab/alpaca": {
            "bleu": 0.01168,
            "rouge": 0.08808
        },
        "truthful_qa": {
            "bleu": 0.00634,
            "rouge": 0.05378
        }
    },
    "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli": {
        "mnli": {
            "accuracy": 0.9
        }
    },
    "UrukHan/t5-russian-summarization": {
        "CarlBrendt/Summ_Dialog_News": {
            "bleu": 0.00482,
            "rouge": 0.08133
        },
        "IlyaGusev/gazeta": {
            "bleu": 0.00134,
            "rouge": 0.09582
        },
        "d0rj/curation-corpus-ru": {
            "bleu": 0.0,
            "rouge": 0.12565
        }
    },
    "VMware/electra-small-mrqa": {
        "HuggingFaceH4/no_robots": {
            "squad": 8.00973
        },
        "lionelchg/dolly_closed_qa": {
            "squad": 19.98425
        },
        "starmpcc/Asclepius-Synthetic-Clinical-Notes": {
            "squad": 3.60667
        }
    },
    "XSY/albert-base-v2-imdb-calssification": {
        "imdb": {
            "f1": 0.74
        }
    },
    "aiknowyou/it-emotion-analyzer": {
        "dair-ai/emotion": {
            "f1": 0.31
        }
    },
    "cointegrated/rubert-base-cased-nli-threeway": {
        "cointegrated/nli-rus-translated-v2021": {
            "accuracy": 0.78
        },
        "xnli": {
            "accuracy": 0.31
        }
    },
    "cointegrated/rubert-tiny-bilingual-nli": {
        "terra": {
            "accuracy": 0.43
        }
    },
    "cointegrated/rubert-tiny-toxicity": {
        "OxAISH-AL-LLM/wiki_toxic": {
            "f1": 0.8
        }
    },
    "cointegrated/rubert-tiny2-cedr-emotion-detection": {
        "seara/ru_go_emotions": {
            "f1": 0.16
        }
    },
    "cross-encoder/qnli-distilroberta-base": {
        "qnli": {
            "accuracy": 0.91
        }
    },
    "dmitry-vorobiev/rubert_ria_headlines": {
        "CarlBrendt/Summ_Dialog_News": {
            "bleu": 0.00126,
            "rouge": 0.04966
        },
        "IlyaGusev/gazeta": {
            "bleu": 0.00038,
            "rouge": 0.09219
        },
        "d0rj/curation-corpus-ru": {
            "bleu": 0.0,
            "rouge": 0.09521
        },
        "trixdade/reviews_russian": {
            "bleu": 1e-05,
            "rouge": 0.0
        }
    },
    "fabriceyhc/bert-base-uncased-ag_news": {
        "ag_news": {
            "f1": 0.96
        }
    },
    "mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization": {
        "ccdv/govreport-summarization": {
            "bleu": 0.0,
            "rouge": 0.07016
        },
        "ccdv/pubmed-summarization": {
            "bleu": 0.00607,
            "rouge": 0.12685
        },
        "cnn_dailymail": {
            "bleu": 0.05655,
            "rouge": 0.22158
        }
    },
    "mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization": {
        "ccdv/govreport-summarization": {
            "bleu": 0.0,
            "rouge": 0.0692
        },
        "ccdv/pubmed-summarization": {
            "bleu": 0.00567,
            "rouge": 0.12992
        },
        "cnn_dailymail": {
            "bleu": 0.05981,
            "rouge": 0.22063
        }
    },
    "nandakishormpai/t5-small-machine-articles-tag-generation": {
        "ccdv/govreport-summarization": {
            "bleu": 0.0,
            "rouge": 0.02879
        },
        "ccdv/pubmed-summarization": {
            "bleu": 0.00047,
            "rouge": 0.07849
        },
        "cnn_dailymail": {
            "bleu": 0.06624,
            "rouge": 0.17864
        }
    },
    "papluca/xlm-roberta-base-language-detection": {
        "papluca/language-identification": {
            "f1": 1.0
        }
    },
    "stevhliu/my_awesome_billsum_model": {
        "CarlBrendt/Summ_Dialog_News": {
            "bleu": 0.00351,
            "rouge": 0.07822
        },
        "d0rj/curation-corpus-ru": {
            "bleu": 0.00072,
            "rouge": 0.12954
        },
        "trixdade/reviews_russian": {
            "bleu": 0.0,
            "rouge": 0.01052
        }
    },
    "t5-small": {
        "RocioUrquijo/en_de": {
            "bleu": 0.24444
        }
    },
    "test_Helsinki-NLP/opus-mt-en-fr": {
        "enimai/MuST-C-fr": {
            "bleu": 0.4468
        }
    },
    "test_VMware/electra-small-mrqa": {
        "starmpcc/Asclepius-Synthetic-Clinical-Notes": {
            "squad": 5.00464
        }
    },
    "test_aiknowyou/it-emotion-analyzer": {
        "dair-ai/emotion": {
            "f1": 0.1
        }
    },
    "test_cointegrated/rubert-base-cased-nli-threeway": {
        "cointegrated/nli-rus-translated-v2021": {
            "accuracy": 0.8
        }
    },
    "test_mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization": {
        "cnn_dailymail": {
            "bleu": 0.04108,
            "rouge": 0.23686
        }
    },
    "test_JackFram/llama-68m": {
        "tatsu-lab/alpaca": {
            "bleu": 0.0,
            "rouge": 0.08789
        }
    },
    "timpal0l/mdeberta-v3-base-squad2": {
        "HuggingFaceH4/no_robots": {
            "squad": 12.68021
        },
        "lionelchg/dolly_closed_qa": {
            "squad": 20.4248
        },
        "starmpcc/Asclepius-Synthetic-Clinical-Notes": {
            "squad": 5.1984
        },
        "sberquad": {
            "squad": 87.31313131313132
        },
        "RussianNLP/wikiomnia": {
            "squad": 39.666666666666664
        }
    },
    "blanchefort/rubert-base-cased-sentiment-rusentiment": {
        "blinoff/kinopoisk": {
            "f1": 0.64
        },
        "blinoff/healthcare_facilities_reviews": {
            "f1": 0.71
        }
    },
    "tatiana-merz/turkic-cyrillic-classifier": {
        "tatiana-merz/cyrillic_turkic_langs": {
            "f1": 0.22
        }
    },
    "s-nlp/russian_toxicity_classifier": {
        "s-nlp/ru_paradetox_toxicity": {
            "f1": 0.73
        },
        "s-nlp/ru_non_detoxified": {
            "f1": 0.77
        },
        "d0rj/rudetoxifier_data": {
            "f1": 1.0
        }
    }
}
